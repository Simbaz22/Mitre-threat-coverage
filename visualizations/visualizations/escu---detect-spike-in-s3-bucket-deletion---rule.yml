title: ESCU - Detect Spike in S3 Bucket deletion - Rule
description: This search detects users creating spikes in API activity related to
  deletion of S3 buckets in your AWS environment. It will also update the cache file
  that factors in the latest data.
status: Active
author: DS
logsource:
  product: Splunk
  service: splunkd
  category: "AWS\nCloud"
detection:
  condition:
    sigma: "`cloudtrail` eventName=DeleteBucket [`cloudtrail` eventName=DeleteBucket\
      \ \n  -  spath output=arn path=userIdentity.arn \n  -  stats count as apiCalls\
      \ by arn \n  -  inputlookup s3_deletion_baseline append=t \n  -  fields - latestCount\
      \ \n  -  stats values(*) as * by arn \n  -  rename apiCalls as latestCount \n\
      \  -  eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 \n  -\
      \  eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720))\
      \ \n  -  eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls,\
      \ stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1)\
      \ \n  -  table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls \n\
      \  -  outputlookup s3_deletion_baseline \n  -  eval dataPointThreshold = 15,\
      \ deviationThreshold = 3 \n  -  eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls)\
      \ AND numDataPoints > dataPointThreshold, 1, 0) \n  -  where isSpike=1 \n  -\
      \  rename arn as userIdentity.arn \n  -  table userIdentity.arn] \n  -  spath\
      \ output=user userIdentity.arn \n  -  spath output=bucketName path=requestParameters.bucketName\
      \ \n  -  stats values(bucketName) as bucketName, count as numberOfApiCalls,\
      \ dc(eventName) as uniqueApisCalled by user \n  -  `detect_spike_in_s3_bucket_deletion_filter`"
  level: critical
tags:
- T1530
- Data from Cloud Storage
- Collection
references: .nan
notes: .nan
